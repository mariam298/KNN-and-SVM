{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UkxsCndm4Wt",
        "outputId": "1495d3e3-f046-4f44-aa8f-a238d4b279b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('titanic_dataset.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "EPpotth7nWrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
      ],
      "metadata": {
        "id": "UmeyB9upm5wS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle missing values"
      ],
      "metadata": {
        "id": "RQvFW2i5njXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing values in the 'Age' column with the median\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Fill missing values in the 'Embarked' column with the mode\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop the 'Cabin' column due to high number of missing values\n",
        "df.drop('Cabin', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L04DKO4Qni3K",
        "outputId": "d642b9a2-1534-4fc1-d48a-3c1fe1b9cb73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode categorical variables"
      ],
      "metadata": {
        "id": "yoGfIm2Xn9Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the 'Sex' column\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode the 'Embarked' column\n",
        "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])\n"
      ],
      "metadata": {
        "id": "SAo1-p9Jnyc6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling:"
      ],
      "metadata": {
        "id": "PwzhsKoMoDJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the numerical features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n"
      ],
      "metadata": {
        "id": "tQ5sR77ZoBg9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into features and target variable:"
      ],
      "metadata": {
        "id": "_Ok9GIfloQfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Survived', axis=1)  # Features\n",
        "y = df['Survived']               # Target variable\n"
      ],
      "metadata": {
        "id": "58AjL9nxoKze"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "i-BR4K2wosph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n"
      ],
      "metadata": {
        "id": "2HgF5yC-oT2r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Outliers"
      ],
      "metadata": {
        "id": "Gitpc0H2o30N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['Fare'].quantile(0.25)\n",
        "Q3 = df['Fare'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Remove outliers below the lower bound\n",
        "df = df[df['Fare'] >= (Q1 - 1.5 * IQR)]\n",
        "\n",
        "# Remove outliers above the upper bound\n",
        "df = df[df['Fare'] <= (Q3 + 1.5 * IQR)]\n"
      ],
      "metadata": {
        "id": "nOdOzA1JozBZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['Age'].quantile(0.25)\n",
        "Q3 = df['Age'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Replace outliers below the lower bound with the median age\n",
        "df.loc[df['Age'] < (Q1 - 1.5 * IQR), 'Age'] = df['Age'].median()\n",
        "\n",
        "# Replace outliers above the upper bound with the median age\n",
        "df.loc[df['Age'] > (Q3 + 1.5 * IQR), 'Age'] = df['Age'].median()\n"
      ],
      "metadata": {
        "id": "SMwXGP-mo7rk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-processed dataset\n",
        "df = pd.read_csv('titanic_dataset.csv')\n",
        "\n",
        "# Remove the 'Name' column\n",
        "df.drop('Name', axis=1, inplace=True)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Continue with the kNN and SVM model creation and evaluation as shown in the previous example\n"
      ],
      "metadata": {
        "id": "_8MA5DEepnhE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "knn and svm models\n"
      ],
      "metadata": {
        "id": "FG1f8kgbpW8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Load the pre-processed dataset\n",
        "df = pd.read_csv('titanic_dataset.csv')\n",
        "\n",
        "# Handle missing values\n",
        "df.fillna(df.median(), inplace=True)\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_columns = df.select_dtypes(exclude=['int', 'float']).columns.tolist()\n",
        "\n",
        "# Encode non-numeric columns\n",
        "label_encoder = LabelEncoder()\n",
        "for column in non_numeric_columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Perform one-hot encoding on remaining categorical columns\n",
        "categorical_columns = ['Pclass', 'SibSp', 'Parch']\n",
        "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "df_encoded = pd.DataFrame(onehot_encoder.fit_transform(df[categorical_columns]))\n",
        "\n",
        "# Create column names for the one-hot encoded features\n",
        "encoded_columns = []\n",
        "for i, col in enumerate(categorical_columns):\n",
        "    for category in onehot_encoder.categories_[i]:\n",
        "        encoded_columns.append(f\"{col}_{category}\")\n",
        "\n",
        "df_encoded.columns = encoded_columns\n",
        "\n",
        "# Concatenate the encoded features with the original dataset and drop the original categorical columns\n",
        "df = pd.concat([df, df_encoded], axis=1).drop(categorical_columns, axis=1)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# kNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(\"kNN Accuracy:\", accuracy_knn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIxFTg75r1UK",
        "outputId": "72d9d739-1666-49db-81f7-f2f2074bb1fb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN Accuracy: 0.6703910614525139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-2866cedc9fd4>:11: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df.fillna(df.median(), inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(\"kNN Accuracy:\", accuracy_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf7MIO-0sTpp",
        "outputId": "a77f145c-4028-4aee-fe92-139ace474b48"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN Accuracy: 0.6703910614525139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# SVM model\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_svm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0U7nJ82sZs4",
        "outputId": "0a7c981c-0f3e-4e43-c960-741c78b56cb4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.6424581005586593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvAvH57WFk-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}